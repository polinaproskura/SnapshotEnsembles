{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_temperature_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "VdSsjRBKkjCj"
      },
      "source": [
        "#@title imports\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import time\n",
        "import copy\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torchvision.models as models\n",
        "import torch, torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "def transform(my_x, my_y):\n",
        "    tensor_x = torch.Tensor(my_x)  # transform to torch tensor\n",
        "    tensor_y = torch.LongTensor(my_y)\n",
        "    my_dataset = data.TensorDataset(tensor_x, tensor_y)  # create your datset\n",
        "    my_dataloader = data.DataLoader(my_dataset)  # create your dataloader\n",
        "    return my_dataloader\n",
        "\n",
        "\n",
        "def compute_loss(X_batch, y_batch):\n",
        "    X_batch = Variable(torch.FloatTensor(X_batch))\n",
        "    y_batch = Variable(torch.LongTensor(y_batch))\n",
        "    X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
        "    logits = resnet18(X_batch)\n",
        "    return F.cross_entropy(logits, y_batch).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "9X3NmX5GkoKl",
        "outputId": "1aacd2ba-f593-4410-ba13-f266187c43e4"
      },
      "source": [
        "#@title dataloading\n",
        "transform = transforms.ToTensor()\n",
        "batch_size=100\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(28, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10('cifar-10', download=True, train=True, transform=transform)\n",
        "testset = datasets.CIFAR10('cifar-10', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "valset, testset = torch.utils.data.random_split(testset, [100, 9900])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Btl5i05lkqps"
      },
      "source": [
        "#@title resnet_structure\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le7_ssJ1Tyaj",
        "outputId": "8b4c4f9c-2a10-45dc-e5f1-68ffae119e15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iyOt5ShVVdE",
        "outputId": "15453e2a-d778-49c3-8a29-6d89fefe8807"
      },
      "source": [
        "! ls /gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\n",
            " CV_2018_actual.pdf\n",
            " CV_2020_nf.pdf\n",
            " CV_2020_sept.pdf\n",
            " CV_project.gdoc\n",
            " CV_project.pdf\n",
            " form2016.gdoc\n",
            "'Getting started.pdf'\n",
            " models\n",
            " Rapport-d-arrivee-non-europeens-etats-tiers_1.gdoc\n",
            " Rapport-d-arrivee-non-europeens-etats-tiers_1.pdf\n",
            " Запрос_Персональные_данные_прием_11.11.2016.docx\n",
            " Запрос_Персональные_данные_прием_11.11.2016.docx.gdoc\n",
            " Математ7-8.docx\n",
            " Математ7-8.docx.gdoc\n",
            "'Мысли по кейсу.gdoc'\n",
            "'Проект по обработке изображений.gdoc'\n",
            " расходы.gsheet\n",
            " Условия\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oaGb7Zat82F"
      },
      "source": [
        "def weigheted_most_common(predictions, weights):\n",
        "    new_predictions = {}\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] in new_predictions:\n",
        "            new_predictions[predictions[i]] = new_predictions[predictions[i]] + weights[i]\n",
        "        else:\n",
        "            new_predictions[predictions[i]] = weights[i]\n",
        "    top = list(sorted(new_predictions.items(), key=lambda item: item[1], reverse=True))\n",
        "    return top[0][0]\n",
        "\n",
        "    \n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "def ensemble_predictions(members, loader, weights):\n",
        "    accs = []\n",
        "    for (X_batch, y_batch) in loader:\n",
        "        yhats = []\n",
        "        for model in members:\n",
        "            y_batch = y_batch.cuda()\n",
        "            logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "            y_pred = logits.max(1)[1].data\n",
        "            yhats.append(y_pred.cpu().numpy())\n",
        "        yhats = np.array(yhats)\n",
        "        maxs = []\n",
        "        for i in range(yhats.shape[1]):\n",
        "            cur_max = weigheted_most_common(yhats[:, i], weights)\n",
        "            maxs.append(cur_max)\n",
        "        # sum across ensemble members\n",
        "        maxs = np.array(maxs)\n",
        "        # argmax across classes\n",
        "        accs.append(np.mean((y_batch.cpu().numpy() == maxs)))\n",
        "    accs = np.array(accs)\n",
        "    return accs, np.mean(accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnCnBCVPUpAa"
      },
      "source": [
        "models_list = []\n",
        "for i in range(25):\n",
        "    name = '/gdrive/MyDrive/models/model_' + str(i) + '.pt'\n",
        "    model = ResNet(BasicBlock, [2,2,2,2]).cuda()\n",
        "    model.load_state_dict(torch.load(name))\n",
        "    models_list.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oYs6-2KVFED",
        "outputId": "88ad06d9-6256-43bb-b93e-dbb4b16a990d"
      },
      "source": [
        "number_of_models = [2, 5, 8, 10, 15, 22]\n",
        "temperatures = [0.1, 0.3, 0.5, 1.0, 1.5, 2.5, 5.0]\n",
        "train_lik_loss = [0.00144718, 0.00157179, 0.00176873, 0.00116637, 0.00341584,\n",
        " 0.00377724, 0.00128005, 0.0016156,  0.00142033, 0.00159872, 0.00143677,\n",
        " 0.00171571, 0.00145743, 0.00149634, 0.00249395, 0.00227039, 0.00293254,\n",
        " 0.00139555, 0.00197147, 0.00150485, 0.00126296, 0.00166432, 0.00153561,\n",
        " 0.00141315, 0.00165902]\n",
        "#train loss\n",
        "\n",
        "results = np.zeros((len(number_of_models), len(temperatures)))\n",
        "for i in range(len(number_of_models)):\n",
        "    num = number_of_models[i]\n",
        "    current_models = models_list[-num:]\n",
        "    for t in range(len(temperatures)):\n",
        "            temp_constant = temperatures[t]\n",
        "            loss_list = np.array(train_lik_loss[-len(current_models):])\n",
        "            for j in range(loss_list.shape[0]):\n",
        "                loss_list[j] = np.exp(loss_list[j] / temp_constant)\n",
        "            weights = np.array(1. / loss_list, dtype=np.float64) #weight according likelyhood \n",
        "            accs, mean_accs = ensemble_predictions(current_models, valloader, weights)\n",
        "            results[i, t] = mean_accs\n",
        "            print(t, 'Ensemble accuracy = ', round(mean_accs, 3) * 100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Ensemble accuracy =  87.0 %\n",
            "1 Ensemble accuracy =  87.0 %\n",
            "2 Ensemble accuracy =  87.0 %\n",
            "3 Ensemble accuracy =  87.0 %\n",
            "4 Ensemble accuracy =  87.0 %\n",
            "5 Ensemble accuracy =  87.0 %\n",
            "6 Ensemble accuracy =  87.0 %\n",
            "0 Ensemble accuracy =  87.0 %\n",
            "1 Ensemble accuracy =  87.0 %\n",
            "2 Ensemble accuracy =  87.0 %\n",
            "3 Ensemble accuracy =  87.0 %\n",
            "4 Ensemble accuracy =  87.0 %\n",
            "5 Ensemble accuracy =  87.0 %\n",
            "6 Ensemble accuracy =  87.0 %\n",
            "0 Ensemble accuracy =  87.0 %\n",
            "1 Ensemble accuracy =  87.0 %\n",
            "2 Ensemble accuracy =  87.0 %\n",
            "3 Ensemble accuracy =  87.0 %\n",
            "4 Ensemble accuracy =  87.0 %\n",
            "5 Ensemble accuracy =  87.0 %\n",
            "6 Ensemble accuracy =  87.0 %\n",
            "0 Ensemble accuracy =  87.0 %\n",
            "1 Ensemble accuracy =  87.0 %\n",
            "2 Ensemble accuracy =  87.0 %\n",
            "3 Ensemble accuracy =  87.0 %\n",
            "4 Ensemble accuracy =  87.0 %\n",
            "5 Ensemble accuracy =  87.0 %\n",
            "6 Ensemble accuracy =  87.0 %\n",
            "0 Ensemble accuracy =  87.0 %\n",
            "1 Ensemble accuracy =  87.0 %\n",
            "2 Ensemble accuracy =  87.0 %\n",
            "3 Ensemble accuracy =  87.0 %\n",
            "4 Ensemble accuracy =  87.0 %\n",
            "5 Ensemble accuracy =  87.0 %\n",
            "6 Ensemble accuracy =  87.0 %\n",
            "0 Ensemble accuracy =  87.0 %\n",
            "1 Ensemble accuracy =  87.0 %\n",
            "2 Ensemble accuracy =  87.0 %\n",
            "3 Ensemble accuracy =  87.0 %\n",
            "4 Ensemble accuracy =  87.0 %\n",
            "5 Ensemble accuracy =  87.0 %\n",
            "6 Ensemble accuracy =  87.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fQ91nc4zVtfM",
        "outputId": "371803dd-9d50-42f7-a985-b9ce0601c3ec"
      },
      "source": [
        "from seaborn import heatmap\n",
        "heatmap(results, xticklabels=temperatures, yticklabels=number_of_models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd0d31d23d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG0VffU6Vtmy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ644YOVVtvQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srkJEP9pkt_n"
      },
      "source": [
        "def cyclical_lr(stepsize, min_lr=3e-4, max_lr=3e-3):\n",
        "\n",
        "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
        "    scaler = lambda x: 1. #* math.exp(-x * 0.1)\n",
        "\n",
        "    # Lambda function to calculate the LR\n",
        "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
        "\n",
        "    # Additional function to see where on the cycle we are\n",
        "    def relative(it, stepsize):\n",
        "        cycle = math.floor(1 + it / (2 * stepsize))\n",
        "        x = abs(it / stepsize - 2 * cycle + 1)\n",
        "        return max(0, (1 - x)) * scaler(cycle)\n",
        "\n",
        "    return lr_lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW9GptFqlfh3",
        "outputId": "cc043afd-64b8-41e5-d16f-27a9e2e8a13e"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "resnet18 = ResNet(BasicBlock, [2,2,2,2])\n",
        "resnet18 = resnet18.cuda()\n",
        "models_list = []\n",
        "prev_model = copy.deepcopy(resnet18)\n",
        "prev_loss = 1000.\n",
        "\n",
        "num_epochs = 351\n",
        "start_lr = 0.01\n",
        "end_lr = 0.1\n",
        "factor = 10\n",
        "\n",
        "opt = torch.optim.SGD(resnet18.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "step_size = 1*len(trainset) / batch_size\n",
        "print(step_size)\n",
        "clr = cyclical_lr(step_size, min_lr=start_lr, max_lr=end_lr)\n",
        "#scheduler = torch.optim.lr_scheduler.LambdaLR(opt, [clr])\n",
        "\n",
        "train_loss = []\n",
        "val_accuracy = []\n",
        "mean_losses = []\n",
        "mean_accs = []\n",
        "models_list = []\n",
        "\n",
        "lr_find_loss = []\n",
        "learning_rates = []\n",
        "likely_loss = []\n",
        "losses = []\n",
        "\n",
        "smoothing = 0.5\n",
        "lrs = []\n",
        "\n",
        "it = 0\n",
        "\n",
        "smoothing = 0.5\n",
        "small_flag = False\n",
        "#scheduler = torch.optim.lr_scheduler.LambdaLR(opt, [clr])\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    resnet18.train(True)\n",
        "    for (X_batch, y_batch) in trainloader:\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        num_loss = loss.data.cpu().numpy()\n",
        "        train_loss.append(num_loss)\n",
        "        if epoch <= 150:\n",
        "            opt.step()\n",
        "        else:\n",
        "            scheduler.step()\n",
        "        opt.zero_grad()\n",
        "        lr_step = opt.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "        if lr_step < 0.001036:\n",
        "            models_list.append(copy.deepcopy(resnet18))\n",
        "            likely_loss.append(num_loss)\n",
        "            if len(models_list) > 25:\n",
        "                models_list = models_list[-25:]\n",
        "        learning_rates.append(lr_step)\n",
        "\n",
        "    if epoch == 150:\n",
        "        scheduler = torch.optim.lr_scheduler.LambdaLR(opt, [clr])  \n",
        "\n",
        "    resnet18.train(False)\n",
        "    for (X_batch, y_batch) in testloader:\n",
        "        y_batch = y_batch.cuda()\n",
        "        logits = resnet18(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "    \n",
        "\n",
        "    mean_accs.append(np.mean(val_accuracy[-len(testset) // batch_size:]))\n",
        "    cur_loss = np.mean(train_loss[-len(trainset) // batch_size:])\n",
        "    mean_losses.append(cur_loss)\n",
        "    \n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "            epoch + 1, num_epochs, time.time() - start_time))\n",
        "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "            np.mean(train_loss[-len(trainset) // batch_size :])))\n",
        "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "            np.mean(val_accuracy[-len(testset) // batch_size :]) * 100))\n",
        "    losses.append(np.array(train_loss).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500.0\n",
            "Epoch 1 of 351 took 73.119s\n",
            "  training loss (in-iteration): \t2.208253\n",
            "  validation accuracy: \t\t\t24.67 %\n",
            "Epoch 11 of 351 took 72.720s\n",
            "  training loss (in-iteration): \t0.553525\n",
            "  validation accuracy: \t\t\t66.82 %\n",
            "Epoch 21 of 351 took 72.425s\n",
            "  training loss (in-iteration): \t0.483124\n",
            "  validation accuracy: \t\t\t68.02 %\n",
            "Epoch 31 of 351 took 72.081s\n",
            "  training loss (in-iteration): \t0.467601\n",
            "  validation accuracy: \t\t\t76.62 %\n",
            "Epoch 41 of 351 took 71.931s\n",
            "  training loss (in-iteration): \t0.448886\n",
            "  validation accuracy: \t\t\t71.81 %\n",
            "Epoch 51 of 351 took 71.995s\n",
            "  training loss (in-iteration): \t0.442036\n",
            "  validation accuracy: \t\t\t71.64 %\n",
            "Epoch 61 of 351 took 71.889s\n",
            "  training loss (in-iteration): \t0.432482\n",
            "  validation accuracy: \t\t\t75.49 %\n",
            "Epoch 71 of 351 took 71.778s\n",
            "  training loss (in-iteration): \t0.422699\n",
            "  validation accuracy: \t\t\t69.77 %\n",
            "Epoch 81 of 351 took 71.647s\n",
            "  training loss (in-iteration): \t0.435560\n",
            "  validation accuracy: \t\t\t70.59 %\n",
            "Epoch 91 of 351 took 71.551s\n",
            "  training loss (in-iteration): \t0.437668\n",
            "  validation accuracy: \t\t\t68.67 %\n",
            "Epoch 101 of 351 took 71.577s\n",
            "  training loss (in-iteration): \t0.437841\n",
            "  validation accuracy: \t\t\t66.85 %\n",
            "Epoch 111 of 351 took 71.601s\n",
            "  training loss (in-iteration): \t0.428752\n",
            "  validation accuracy: \t\t\t74.63 %\n",
            "Epoch 121 of 351 took 71.400s\n",
            "  training loss (in-iteration): \t0.430895\n",
            "  validation accuracy: \t\t\t73.98 %\n",
            "Epoch 131 of 351 took 71.423s\n",
            "  training loss (in-iteration): \t0.435102\n",
            "  validation accuracy: \t\t\t77.96 %\n",
            "Epoch 141 of 351 took 71.277s\n",
            "  training loss (in-iteration): \t0.421750\n",
            "  validation accuracy: \t\t\t66.23 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqUTAxozoMN_"
      },
      "source": [
        "original_likely_loss = likely_loss.copy() # only for train\n",
        "print(original_likely_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64wCl_LbuC6i"
      },
      "source": [
        "temps = [0.1, 0.3, 0.5, 0.8, 1.1, 1.5,]\n",
        "ens_accs = []\n",
        "lik_loss = original_likely_loss.copy()\n",
        "print(len(models_list))\n",
        "for t in temps:\n",
        "    temp_constant = t\n",
        "    loss_list = np.array(lik_loss[-len(models_list):])\n",
        "    for i in range(loss_list.shape[0]):\n",
        "        loss_list[i] = np.exp(loss_list[i] / temp_constant)\n",
        "    weights = np.array(1. / loss_list, dtype=np.float64) #weight according likelyhood \n",
        "    #print(weights)\n",
        "    accs, mean_accs = ensemble_predictions(models_list, testloader, weights)\n",
        "    ens_accs.append(mean_accs)\n",
        "    print(t, 'Ensemble accuracy = ', round(mean_accs, 3) * 100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yjaoVEpuMTx"
      },
      "source": [
        "plt.plot(temps, ens_accs)\n",
        "plt.title('Weights according train loss')\n",
        "plt.xlabel('temperature')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co0x8cG5ukU1"
      },
      "source": [
        "#aacuracy of every one\n",
        "for model in models_list:\n",
        "  accuracy = []\n",
        "  for (X_batch, y_batch) in testloader:\n",
        "          y_batch = y_batch.cuda()\n",
        "          logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "          y_pred = logits.max(1)[1].data\n",
        "          accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "  print(np.array(accuracy).mean() * 100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPwLLbjrukTh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r94lqWlEukSL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}